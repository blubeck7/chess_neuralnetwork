{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load packages\n",
    "import sys\n",
    "sys.path.append(\"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/\")\n",
    "import boto3\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import vstack as vstack\n",
    "import chess, chess.pgn\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import gzip\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "BOARD_LENGTH = 768 #chess board is 8 x 8 and 12 different pieces\n",
    "\n",
    "## Vector representation of chess board\n",
    "# v = 1 x BOARD_LENGTH\n",
    "#\n",
    "# White = Upper Case, black = lower case\n",
    "# Piece order: P, N, B, R, Q, K, p, n, b, r, q, k\n",
    "# Board order:\n",
    "#    Start at square a1. Move across the columns to square h1.\n",
    "#    Then go up a row to square a2. Move across the columns to square h2.\n",
    "#    Repeat until square h8\n",
    "#    i.e. 0 - a1, 1 - b1, ..., 7 - h1, 8 - a2, ..., 63 - h8\n",
    "#\n",
    "# Board vector indices: \n",
    "# v[0,...,63] = P, v[64,...,127] = N, ..., v[704,...,767] = k\n",
    "# v[0,...,7] = row 1; v[8,...,15] = row 2, ..., v[56,...,63] = row 8\n",
    "# v[0] = col a, v[1] = col b, ..., v[7] = col h\n",
    "\n",
    "PIECE_OFFSETS = {'P': 0, 'N': 64, 'B': 128, 'R': 192, 'Q': 256, 'K': 320,\n",
    "                 'p': 384, 'n': 448, 'b': 512, 'r': 576, 'q': 640, 'k': 704}\n",
    "\n",
    "RESULTS_DICT = {'1-0': 1,'1/2-1/2': 0,'0-1': -1}\n",
    "RESULTS_LIST = [1, 0, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net\n",
    "\n",
    "In this section, we build, train and test a feedforward neural network that calculates the probability a board position results in a win for white. We first use a small sample of games to determine a reasonable number of hidden nodes fro the neural network. The program ParseData.py converts the pgn data into binary vectors and saves the output. The program PrepareTrainTest.py takes the binary vectors and creates four training datasets and one testing dataset. We split the data up so that the data could be processed by different cores using mini-batch parallelism. We compare the time to train the neural network of our implementation of mini-batch parallelism versus none."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net Class\n",
    "\n",
    "The code uses sparse matrices to siginificantly decrease the amount of memory and instructions needed on a CPU to train the neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BoardFunction:\n",
    "    \n",
    "    def __init__(self, numInputNodes, numHiddenNodes, numOutputNodes, maxIter, maxEpochs):\n",
    "        # layers\n",
    "        self.numInputNodes = numInputNodes\n",
    "        self.numHiddenNodes = numHiddenNodes\n",
    "        self.numOutputNodes = numOutputNodes\n",
    "        \n",
    "        # weight matrices\n",
    "        self.hiddenWeights = np.empty((self.numInputNodes, self.numHiddenNodes), dtype = np.float_)\n",
    "        self.hiddenBiases = np.empty((1, self.numHiddenNodes), dtype = np.float_)\n",
    "        self.outputWeights = np.empty((self.numHiddenNodes, self.numOutputNodes), dtype = np.float_)\n",
    "        self.outputBiases = np.empty((1, self.numOutputNodes), dtype = np.float_)\n",
    "        \n",
    "        # learning parameters\n",
    "        self.learningRate = 0.1\n",
    "        self.minRate = 0.00001\n",
    "        self.miniBatchSize = 512\n",
    "        self.maxIter = maxIter\n",
    "        self.maxEpochs = maxEpochs\n",
    "        self.minTol = 10**(-7)\n",
    "        self.decay = True # if true decreses the learning rate if loss plateaus\n",
    "        self.logPath = '../log'\n",
    "        \n",
    "    def initWeights(self, seed = None):\n",
    "        '''\n",
    "        Randomly initializes the weight matrices\n",
    "        '''\n",
    "        if seed != None:\n",
    "            np.random.seed(seed)\n",
    "            \n",
    "        self.hiddenWeights = np.random.normal(loc = 0.1, size = self.hiddenWeights.shape)\n",
    "        self.hiddenBiases = np.random.normal(loc = 0.1, size = self.hiddenBiases.shape)\n",
    "        self.outputWeights = np.random.normal(loc = 0.1, size = self.outputWeights.shape)\n",
    "        self.outputBiases = np.random.normal(loc = 0.1, size = self.outputBiases.shape)\n",
    "        \n",
    "    def _relu(self, X):\n",
    "        '''\n",
    "        X - matrix\n",
    "        \n",
    "        returns element wise max of X and zero\n",
    "        '''\n",
    "        \n",
    "        return(np.maximum(X,0))\n",
    "    \n",
    "    def _softmax(self, X):\n",
    "        shiftX = X - np.amax(X, axis = 1, keepdims = True)\n",
    "        exps = np.exp(shiftX)\n",
    "        sums = np.sum(exps, axis = 1, keepdims = True)\n",
    "        \n",
    "        return(exps / sums)\n",
    "    \n",
    "    def predict(self, board):\n",
    "        '''\n",
    "        board - csr matrix: sparse row matrix of encoded board positions\n",
    "    \n",
    "        returns probs - numpy array: a matrix containing the probability of a win, draw or loss\n",
    "        '''\n",
    "        \n",
    "        numBoards = board.shape[0]\n",
    "        \n",
    "        hiddenWeights = board.dot(self.hiddenWeights)\n",
    "        hiddenBiases = np.outer(np.ones((numBoards, 1), dtype = np.float_), self.hiddenBiases)\n",
    "        hiddenIn = hiddenWeights + hiddenBiases\n",
    "        hiddenOut = self._relu(hiddenIn) #rectified linear element-wise max with zero\n",
    "        \n",
    "        outputWeights = hiddenOut.dot(self.outputWeights)\n",
    "        outputBiases = np.outer(np.ones((numBoards, 1), dtype = np.float_), self.outputBiases)\n",
    "        outputIn = outputWeights + outputBiases\n",
    "        outputOut = self._softmax(outputIn)\n",
    "        \n",
    "        minProb = np.finfo(np.float64).tiny # avoid numerical issues with zero probs\n",
    "        \n",
    "        return(np.maximum(outputOut, minProb))\n",
    "    \n",
    "    def loss(self, board, result):\n",
    "        '''\n",
    "        board - csr matrix: sparse row matrix of encoded board positions\n",
    "        result - 1d array: one hot enconding of result\n",
    "        \n",
    "        returns the cross entropy (multinomial log-likelihood) for the sample\n",
    "        '''\n",
    "        \n",
    "        probs = self.predict(board)\n",
    "        aveLogLikelihood = -np.sum(result * np.log(probs)) / board.shape[0]\n",
    "        \n",
    "        return(aveLogLikelihood)\n",
    "    \n",
    "    def calcGradients(self, board, result):\n",
    "        '''\n",
    "        board - csr matrix: sparse row matrix of encoded board positions\n",
    "        result - 1d array: one hot enconding of result\n",
    "        \n",
    "        J = cross entropy loss function\n",
    "        '''\n",
    "        \n",
    "        numBoards = board.shape[0]\n",
    "        \n",
    "        # feed forward\n",
    "        hiddenWeights = board.dot(self.hiddenWeights)\n",
    "        hiddenBiases = np.outer(np.ones((numBoards, 1), dtype = np.float_), self.hiddenBiases)\n",
    "        hiddenIn = hiddenWeights + hiddenBiases\n",
    "        hiddenOut = self._relu(hiddenIn) #rectified linear element-wise max with zero\n",
    "        \n",
    "        outputWeights = hiddenOut.dot(self.outputWeights)\n",
    "        outputBiases = np.outer(np.ones((numBoards, 1), dtype = np.float_), self.outputBiases)\n",
    "        outputIn = outputWeights + outputBiases\n",
    "        outputOut = self._softmax(outputIn)\n",
    "        \n",
    "        # compute gradients\n",
    "        d1 = outputOut - result\n",
    "        d2 = d1.dot(self.outputWeights.transpose()) * np.sign(hiddenOut)\n",
    "        \n",
    "        # D J(outputWeights)\n",
    "        DJoutW = hiddenOut.transpose().dot(d1) / numBoards\n",
    "        \n",
    "        # D J(outputBiases)\n",
    "        DJoutB = np.sum(d1.dot(np.eye(result.shape[1])), axis = 0) / numBoards\n",
    "        \n",
    "        # D J(hiddenWeights)\n",
    "        DJhidW = board.transpose().dot(d2) / numBoards\n",
    "        \n",
    "        # D J(hiddenBiases)\n",
    "        DJhidB = np.sum(d2, axis = 0) / numBoards\n",
    "        \n",
    "        return(DJoutW, DJoutB, DJhidW, DJhidB)\n",
    "    \n",
    "    def saveIter(self, fileName, fileNum, numEpoch, numIter, loss):\n",
    "        line = str(fileNum) + ',' + str(numEpoch) + ',' + str(numIter) + ',' + str(loss) + '\\n'\n",
    "        with open(fileName, mode ='a') as f:\n",
    "            f.write(line)\n",
    "    \n",
    "    def saveWeights(self, fileName):\n",
    "        print('Saving weights to ' + fileName)\n",
    "        np.savez_compressed(fileName,\n",
    "                            hiddenWeights = self.hiddenWeights,\n",
    "                            hiddenBiases = self.hiddenBiases,\n",
    "                            outputWeights = self.outputWeights,\n",
    "                            outputBiases = self.outputBiases)\n",
    "        print('Done saving weights')\n",
    "        \n",
    "    def applyGradients(self, DJoutW, DJoutB, DJhidW, DJhidB):\n",
    "        '''\n",
    "        \n",
    "        updates each weight matrix by subtracting off the learning rate times the gradient\n",
    "        '''\n",
    "        \n",
    "        self.hiddenWeights = self.hiddenWeights - self.learningRate * DJhidW\n",
    "        self.hiddenBiases = self.hiddenBiases - self.learningRate * DJhidB\n",
    "        self.outputWeights = self.outputWeights - self.learningRate * DJoutW\n",
    "        self.outputBiases = self.outputBiases - self.learningRate * DJoutB\n",
    "    \n",
    "    def train(self, xTrain, yTrain, logFile, fileNum):\n",
    "        \n",
    "        # setup training\n",
    "        resultOneHot = MultiLabelBinarizer(classes = RESULTS_LIST)\n",
    "        batchFeeder = self.nextBatch(xTrain.shape[0], self.miniBatchSize)\n",
    "    \n",
    "        numIter = 0\n",
    "        changedEpoch = 1\n",
    "        loss = np.zeros(10, dtype=np.float_) # saves the 10 previous checkpoint losses\n",
    "        stop = False\n",
    "        \n",
    "        print('Start training hidden nodes ' + str(self.numHiddenNodes))\n",
    "        print('Learning rate is {}'.format(self.learningRate))\n",
    "    \n",
    "        while stop == False:\n",
    "            # get batch\n",
    "            firstInd, lastInd, numEpoch = next(batchFeeder)\n",
    "            board = xTrain[firstInd:lastInd]\n",
    "            result = resultOneHot.fit_transform(yTrain[firstInd:lastInd])\n",
    "            \n",
    "            # calc and save loss every 50 iterations\n",
    "            if numIter % 50 == 0:\n",
    "                i = (numIter // 50) % 10\n",
    "                loss[i] = self.loss(board, result)\n",
    "                #print('Iteration: {0} Loss: {1}'.format(numIter, loss[i]))\n",
    "                self.saveIter(logFile, fileNum, numEpoch, numIter, loss[i])\n",
    "            \n",
    "            # save parameters\n",
    "            if numIter % 10000 == 0:\n",
    "                # save parameters\n",
    "                print('Saving weights learned so far')\n",
    "                boardFunc.saveWeights(modelFile)\n",
    "        \n",
    "            # calc and apply gradients\n",
    "            DJoutW, DJoutB, DJhidW, DJhidB = self.calcGradients(board, result)\n",
    "            self.applyGradients(DJoutW, DJoutB, DJhidW, DJhidB)\n",
    "        \n",
    "            # update number of iterations\n",
    "            numIter = numIter + 1\n",
    "        \n",
    "            # check if max number of iterations or epochs\n",
    "            if numIter > self.maxIter or numEpoch > self.maxEpochs:\n",
    "                stop = True\n",
    "                self.saveIter(logFile, fileNum, numEpoch - 1, numIter - 1, loss[i])\n",
    "                print('Stopped training at {} iterations and {} epochs for hidden nodes {}'.format(\n",
    "                    numIter, numEpoch, self.numHiddenNodes))\n",
    "                \n",
    "            # if decay is true change learning rate at epoch\n",
    "            if self.decay == True and numEpoch - changedEpoch > 10:\n",
    "                changedEpoch = numEpoch\n",
    "                self.learningRate = self.learningRate / 10\n",
    "                print('Epoch {}. Changed learning rate to {}'.format(numEpoch, self.learningRate))\n",
    "\n",
    "    \n",
    "    def nextBatch(self, totObs, batchSize):\n",
    "        # initialize\n",
    "        numBatches = totObs // batchSize\n",
    "        tail = totObs % batchSize\n",
    "        batch = 0\n",
    "        epoch = 0\n",
    "    \n",
    "        # generator\n",
    "        while True:\n",
    "            batch = (batch + 1) % numBatches\n",
    "            if batch == 1:\n",
    "                firstInd = 0\n",
    "                lastInd = batchSize\n",
    "                epoch = epoch + 1\n",
    "            elif batch == 0:\n",
    "                firstInd = lastInd\n",
    "                lastInd = lastInd + batchSize + tail\n",
    "            else:\n",
    "                firstInd = lastInd\n",
    "                lastInd = lastInd + batchSize\n",
    "        \n",
    "            yield firstInd, lastInd, epoch\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net Built on Sample Data\n",
    "\n",
    "We build a neural net on a sample of data in order to determine a resonable number of hidden nodes to use to\n",
    "train the full model. We use a sample of data so that the training times are short enough that the model can be iterated on as a function of number of hidden nodes on a laptop. First, we write the code to implement a feed forward neural network with one hidden layer. The hidden layer uses the rectified linear function, and the output layer uses the softmax function. Cross-entropy (multinomial likelihood) is used as the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load sample data\n",
    "dataDir = '../test/clean'\n",
    "xTrainFiles = [os.path.join(dataDir, 'xTrain'+str(i)+'.npz') for i in range(os.cpu_count())]\n",
    "yTrainFiles = [os.path.join(dataDir, 'yTrain'+str(i)+'.npz') for i in range(os.cpu_count())]\n",
    "xTrain_ = []\n",
    "yTrain_ = []\n",
    "\n",
    "for fx, fy in zip(xTrainFiles,yTrainFiles):\n",
    "    xTrain_.append(scipy.sparse.load_npz(fx))\n",
    "    yTrain_.append(np.load(fy)['arr_0'])\n",
    "    \n",
    "xTrain1 = scipy.sparse.vstack(xTrain_)\n",
    "yTrain1 = np.concatenate(yTrain_)\n",
    "\n",
    "xTest1 = scipy.sparse.load_npz(os.path.join(dataDir, 'xTest.npz'))\n",
    "yTest1 = np.load(os.path.join(dataDir, 'yTest.npz'))['arr_0']\n",
    "\n",
    "del [xTrain_, yTrain_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define worker function for bias-variance graph\n",
    "def evalNumHiddenNodes(numHiddenNodes):\n",
    "    '''\n",
    "    numHiddenNodes - int: number of hidden nodes\n",
    "    \n",
    "    returns tuple of training loss and testing loss\n",
    "    '''\n",
    "    \n",
    "    resultOneHot = MultiLabelBinarizer(classes = RESULTS_LIST)\n",
    "    trainingLoss = 0\n",
    "    testingLoss = 0\n",
    "    \n",
    "    print('Hidden Nodes {}'.format(numHiddenNodes))\n",
    "    \n",
    "    for i in range(4):\n",
    "        print('Hidden Nodes {} round {}'.format(numHiddenNodes, i))\n",
    "        xTrain_, xTest_, yTrain_, yTest_ = train_test_split(vstack((xTrain,xTest)), np.vstack((yTrain,yTest)),\n",
    "                                                            train_size = 0.8, random_state = i + 1)\n",
    "        f = BoardFunction(BOARD_LENGTH, numHiddenNodes, 3, 200000, 20)\n",
    "        f.initWeights(i + 1) #set seed for reproducibility\n",
    "        f.train(xTrain_, yTrain_)\n",
    "        trainingLoss = trainingLoss + f.loss(xTrain_, resultOneHot.fit_transform(yTrain_)) / 4\n",
    "        testingLoss = testingLoss + f.loss(xTest_, resultOneHot.fit_transform(yTest_)) / 4\n",
    "    \n",
    "    return(trainingLoss, testingLoss)\n",
    "\n",
    "def worker(taskQueue, outQueue):\n",
    "    while not taskQueue.empty():\n",
    "        n = taskQueue.get()\n",
    "        trainingLoss, testingLoss = evalNumHiddenNodes(n)\n",
    "        outQueue.put((n, trainingLoss, testingLoss))\n",
    "\n",
    "def main():\n",
    "    # set number of processes to number of cores\n",
    "    numProcesses = os.cpu_count()\n",
    "    \n",
    "    # create queues\n",
    "    taskQueue = mp.Queue()\n",
    "    outQueue = mp.Queue()\n",
    "\n",
    "    # create task queue with range of hidden nodes to evaluate\n",
    "    # hiddenNodes = [2, 3, 5] + [i for i in range(10,100,10)] + [i for i in range(100,1100,100)]\n",
    "    hiddenNodes = [2000]\n",
    "    # submit tasks\n",
    "    for i in hiddenNodes:\n",
    "        taskQueue.put(i)\n",
    "        \n",
    "    # Start worker processes\n",
    "    workers = []\n",
    "    for i in range(numProcesses):\n",
    "        workers.append(mp.Process(target=worker, args=(taskQueue, outQueue)))\n",
    "        workers[i].daemon = True\n",
    "        workers[i].start()\n",
    "    \n",
    "    # Block until all items in the queue have been retrieved and processed.\n",
    "    for w in workers:\n",
    "        w.join()\n",
    "        \n",
    "    # Get and print results\n",
    "    print('Results:')\n",
    "    for i in range(len(hiddenNodes)):\n",
    "        print('\\t', outQueue.get())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net of Full Data\n",
    "\n",
    "Based on data below, it appears that 100 is a reasonable number of hidden nodes for 294,428 total board positions in the data (of which 261,013 are unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataDir = '../data/clean'\n",
    "xTrainFiles = [os.path.join(dataDir, 'xTrain' + str(i) + '.npz') for i in range(4)]\n",
    "yTrainFiles = [os.path.join(dataDir, 'yTrain' + str(i) + '.npz') for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# initialize model\n",
    "logFile = '../log/model_full_log.txt'\n",
    "modelFile = '../model/model_full_weights.npz'\n",
    "boardFunc = BoardFunction(BOARD_LENGTH, 32000, 3, 200000, 1)\n",
    "boardFunc.initWeights()\n",
    "\n",
    "# load through data files and train\n",
    "for fx, fy, fileNum in zip(xTrainFiles, yTrainFiles, range(4)):\n",
    "    # load data file\n",
    "    xTrain = scipy.sparse.load_npz(fx)\n",
    "    yTrain = np.load(fy)['arr_0']\n",
    "    \n",
    "    # train on data chunk\n",
    "    print('File ' + str(fileNum))\n",
    "    boardFunc.train(xTrain, yTrain, logFile, fileNum)\n",
    "    # save parameters\n",
    "    boardFunc.saveWeights(modelFile)\n",
    "    # change learning rate\n",
    "    boardFunc.learningRate = boardFunc.learningRate\n",
    "    print()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boardFunc.outputBiases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# memory usage in GiB\n",
    "dataGiB = xTrain.nnz * xTrain.dtype.itemsize / (1024**3)\n",
    "colGiB = xTrain.indices.shape[0] * xTrain.indices.dtype.itemsize / (1024**3)\n",
    "rowGiB = xTrain.indptr.shape[0] * xTrain.indptr.dtype.itemsize / (1024**3)\n",
    "print('Boards total GiB: ' + str(dataGiB + colGiB + rowGiB))\n",
    "\n",
    "dataGiB = yTrain.shape[0] * yTrain.dtype.itemsize / (1024**3)\n",
    "print('Results total GiB: ' + str(dataGiB))\n",
    "\n",
    "print('Number of Board Positions: ' + str(xTrain.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes for Report\n",
    "\n",
    "From Nitish Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, Ping Tak Peter Tang. On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima. https://arxiv.org/abs/1609.04836 :\n",
    "\n",
    "The stochastic gradient descent method and its variants are algorithms of choice for many Deep Learning tasks. These methods operate in a small-batch regime wherein a fraction of the training data, usually 32--512 data points, is sampled to compute an approximation to the gradient. It has been observed in practice that when using a larger batch there is a significant degradation in the quality of the model, as measured by its ability to generalize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results of Training on Small sample\n",
    "\n",
    "Hidden Nodes | Training Loss | Testing Loss\n",
    "\n",
    "(2, 1.0100619674035751, 1.0091796152110315)  \n",
    "(3, 1.007482207571287, 1.0066383559043466)  \n",
    "(5, 1.0055554590398994, 1.005023531581839)  \n",
    "(10, 1.0025096545121017, 1.0014980079650992)  \n",
    "(20, 0.99807602689486419, 0.99720644407485393)  \n",
    "(30, 0.99399420182901932, 0.99333884848858678)  \n",
    "(40, 0.99328607731974783, 0.99274053552888364)  \n",
    "(50, 0.98944021407430505, 0.98889769712408171)  \n",
    "(60, 0.9863994075288971, 0.98619975531255344)  \n",
    "(70, 0.9840429241801889, 0.98366685082558569)  \n",
    "(80, 0.98182486550393266, 0.98176263405153508)  \n",
    "(90, 0.98028274459491105, 0.980031350473068)  \n",
    "(100, 0.9799195740106964, 0.98035206647664563)  \n",
    "(200, 0.96067535070753229, 0.96146881491348635)  \n",
    "(300, 0.94619056342381636, 0.94883739830555913)  \n",
    "(400, 0.93211902538475155, 0.93581461710661318)  \n",
    "(500, 0.92147218306629264, 0.92625700867560345)  \n",
    "(600, 0.91413918085285739, 0.91944739566420786)  \n",
    "(700, 0.90181913873124897, 0.90894246695116876)  \n",
    "(800, 0.89781815061434322, 0.90720724133753783)  \n",
    "(900, 0.90179592770302441, 0.91455607692081964)  \n",
    "(1000, 0.90999905019713589, 0.92927055677816228)  \n",
    "(1100, 0.91730496589972221, 0.94067571972455488)  \n",
    "(1200, 0.93264025467090339, 0.96354963998689114)  \n",
    "(1300, 1.0002378034267088, 1.0420546608713139)  \n",
    "(1400, 1.0517057482093932, 1.1026789728980475)  \n",
    "(1500, 1.1478033939379304, 1.221898995717857)  \n",
    "(1600, 1.2890920718141325, 1.3911260895054278)  \n",
    "(1700, 1.3804783955461297, 1.5090146237581545)  \n",
    "(1800, 1.4683900170764266, 1.6101375997534371)  \n",
    "(1900, 1.6144862319988333, 1.7925763627477731)  \n",
    "(2000, 1.7326184003683225, 1.9542765976494103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertBoardToVec(board):\n",
    "    '''convertBoardToVec(board object) -> array\n",
    "        \n",
    "        board object = object of Board Class from chess,\n",
    "        array = 1d np array of length BOARD_LENGTH\n",
    "        \n",
    "    This function loops converts a board to its corresponding vector representation\n",
    "    '''\n",
    "    \n",
    "    v = np.zeros(BOARD_LENGTH, dtype = np.int8)\n",
    "\n",
    "    pieces = board.piece_map()\n",
    "    for sq in pieces:\n",
    "        piece = pieces[sq]\n",
    "        ind = PIECE_OFFSETS[piece.symbol()] + sq\n",
    "        v[ind] = 1\n",
    "        \n",
    "    return(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = BoardFunction(BOARD_LENGTH, 10, 3, 200000, 20)\n",
    "f.initWeights(1) #set seed for reproducibility\n",
    "f.train(xTrain, yTrain)\n",
    "resultOneHot = MultiLabelBinarizer(classes = RESULTS_LIST)\n",
    "trainingLoss = f.loss(xTrain, resultOneHot.fit_transform(yTrain))\n",
    "testingLoss = f.loss(xTest, resultOneHot.fit_transform(yTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(trainingLoss, testingLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# layer parameters\n",
    "numInputNodes = BOARD_LENGTH\n",
    "numHiddenNodes = 32000\n",
    "numOutputNodes = 3\n",
    "\n",
    "# input and output placeholders\n",
    "#x = tf.sparse_placeholder(tf.float64, shape = [None, numInputNodes])\n",
    "x = tf.placeholder(tf.float64, shape = [None, numInputNodes])\n",
    "y = tf.placeholder(tf.float64, shape = [None, numOutputNodes])\n",
    "\n",
    "# layer weights and biases\n",
    "hiddenWeights = tf.Variable(evalFunc.hiddenWeights)\n",
    "hiddenBiases = tf.Variable(evalFunc.hiddenBiases)\n",
    "outputWeights = tf.Variable(evalFunc.outputWeights)\n",
    "outputBiases = tf.Variable(evalFunc.outputBiases)\n",
    "\n",
    "# computations\n",
    "# hidden = tf.nn.relu(tf.add(tf.sparse_tensor_dense_matmul(x, hiddenWeights), hiddenBiases))\n",
    "hidden = tf.nn.relu(tf.add(tf.matmul(x, hiddenWeights), hiddenBiases))\n",
    "output = tf.add(tf.matmul(hidden, outputWeights), outputBiases)\n",
    "\n",
    "# probs\n",
    "tf.nn.softmax_cross_entropy_with_logits(labels = y, logits = output)\n",
    "# cost function\n",
    "# cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y, logits = output))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    currCost = sess.run([cost], feed_dict = {x: xTest.toarray(), y: resultOneHot.fit_transform(yTest)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "currCost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code to transform model weights to c\n",
    "#Read in weights and export as csv file\n",
    "weights = np.load('../model/model_full_weights.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hw = weights['hiddenWeights']\n",
    "hb = weights['hiddenBiases']\n",
    "ow = weights['outputWeights']\n",
    "ob = weights['outputBiases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hw.tofile('../model/hw_weights')\n",
    "hb.tofile('../model/hb_weights')\n",
    "ow.tofile('../model/ow_weights')\n",
    "ob.tofile('../model/ob_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hw[2][0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hb[0][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(ow[2][0:3])\n",
    "print(ow[3][0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ob[0][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evalFunc = BoardFunction(768,32000,3,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evalFunc.hiddenWeights = hw\n",
    "evalFunc.hiddenBiases = hb\n",
    "evalFunc.outputWeights = ow\n",
    "evalFunc.outputBiases = ob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "board = np.zeros(shape = (1,768));\n",
    "board[0,100] = 1;\n",
    "board[0,200] = 1;\n",
    "board[0,300] = 1;\n",
    "board[0,88] = 1;\n",
    "board[0,400] = 1;\n",
    "board[0,500] = 1;\n",
    "board[0,542] = 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.95302613,  0.01882871,  0.02814516]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalFunc.predict(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9248809684958742"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(evalFunc.predict(board) * np.array([[1,0,-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numBoards = 1\n",
    "        \n",
    "hiddenWeights = board.dot(evalFunc.hiddenWeights)\n",
    "hiddenBiases = np.outer(np.ones((numBoards, 1), dtype = np.float_), evalFunc.hiddenBiases)\n",
    "hiddenIn = hiddenWeights + hiddenBiases\n",
    "hiddenOut = evalFunc._relu(hiddenIn) #rectified linear element-wise max with zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.53140389 -0.05436956 -1.55526973  0.79106861  0.83817631  0.41159211\n",
      " -0.26906471  0.74794157 -1.27518978 -2.40060382]\n",
      "[-2.23596907 -1.02252381 -1.48166693 -1.85591248 -2.50453441]\n",
      "[-3.82736216 -1.75827792 -1.79254594 -1.6382281  -2.44271143]\n",
      "[ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.02663283  0.          0.          0.          0.08756336\n",
      "  0.          2.21515236  0.          0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(hiddenWeights[0,120:130])\n",
    "print(hiddenBiases[0,0:5])\n",
    "print(hiddenIn[0,0:5])\n",
    "print(hiddenOut[0,450:470])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputWeights = hiddenOut.dot(evalFunc.outputWeights)\n",
    "outputBiases = np.outer(np.ones((numBoards, 1), dtype = np.float_), evalFunc.outputBiases)\n",
    "outputIn = outputWeights + outputBiases\n",
    "outputOut = evalFunc._softmax(outputIn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -4.61338212  10.56582991  12.35300495]]\n",
      "[[ 0.82741939 -0.66027762  0.7655464 ]]\n",
      "[[ -3.78596273   9.90555229  13.11855135]]\n",
      "[[  4.37855709e-08   3.86794631e-02   9.61320493e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(outputWeights)\n",
    "print(outputBiases)\n",
    "print(outputIn)\n",
    "print(outputOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.3786734226554488e-08"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-3.785946) / (np.exp(-3.785946) + np.exp(9.905580) + np.exp(13.118540))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03868091562129812"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(9.905580)/ (np.exp(-3.785946) + np.exp(9.905580) + np.exp(13.118540))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96131904059196771"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(13.118540) / (np.exp(-3.785946) + np.exp(9.905580) + np.exp(13.118540))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09734647044120374"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2**9.905580)/ ((2**-3.785946) + (2**9.905580) + (2**13.118540))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022184091213665616"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/(1+ np.exp(3.785946))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0098208119746326268"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/(1+ np.exp(4.61338212))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/Users/brianlubeck/anaconda/lib/python36.zip',\n",
       " '/Users/brianlubeck/anaconda/lib/python3.6',\n",
       " '/Users/brianlubeck/anaconda/lib/python3.6/lib-dynload',\n",
       " '/Users/brianlubeck/anaconda/lib/python3.6/site-packages',\n",
       " '/Users/brianlubeck/anaconda/lib/python3.6/site-packages/Sphinx-1.5.1-py3.6.egg',\n",
       " '/Users/brianlubeck/anaconda/lib/python3.6/site-packages/aeosa',\n",
       " '/Users/brianlubeck/anaconda/lib/python3.6/site-packages/setuptools-27.2.0-py3.6.egg',\n",
       " '/Users/brianlubeck/anaconda/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/Users/brianlubeck/.ipython',\n",
       " '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.3'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Training graph\n",
    "\n",
    "d = [2, 1.0100619674035751, 1.0091796152110315,\n",
    "3, 1.007482207571287, 1.0066383559043466,\n",
    "5, 1.0055554590398994, 1.005023531581839,\n",
    "10, 1.0025096545121017, 1.0014980079650992,\n",
    "20, 0.99807602689486419, 0.99720644407485393,\n",
    "30, 0.99399420182901932, 0.99333884848858678,\n",
    "40, 0.99328607731974783, 0.99274053552888364,\n",
    "50, 0.98944021407430505, 0.98889769712408171,\n",
    "60, 0.9863994075288971, 0.98619975531255344,\n",
    "70, 0.9840429241801889, 0.98366685082558569,\n",
    "80, 0.98182486550393266, 0.98176263405153508,\n",
    "90, 0.98028274459491105, 0.980031350473068,\n",
    "100, 0.9799195740106964, 0.98035206647664563,\n",
    "200, 0.96067535070753229, 0.96146881491348635,\n",
    "300, 0.94619056342381636, 0.94883739830555913,\n",
    "400, 0.93211902538475155, 0.93581461710661318,\n",
    "500, 0.92147218306629264, 0.92625700867560345,\n",
    "600, 0.91413918085285739, 0.91944739566420786,\n",
    "700, 0.90181913873124897, 0.90894246695116876,\n",
    "800, 0.89781815061434322, 0.90720724133753783,\n",
    "900, 0.90179592770302441, 0.91455607692081964,\n",
    "1000, 0.90999905019713589, 0.92927055677816228,\n",
    "1100, 0.91730496589972221, 0.94067571972455488,\n",
    "1200, 0.93264025467090339, 0.96354963998689114,\n",
    "1300, 1.0002378034267088, 1.0420546608713139,\n",
    "1400, 1.0517057482093932, 1.1026789728980475,\n",
    "1500, 1.1478033939379304, 1.221898995717857,\n",
    "1600, 1.2890920718141325, 1.3911260895054278,\n",
    "1700, 1.3804783955461297, 1.5090146237581545,\n",
    "1800, 1.4683900170764266, 1.6101375997534371,\n",
    "1900, 1.6144862319988333, 1.7925763627477731,\n",
    "2000, 1.7326184003683225, 1.9542765976494103]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Results of Training on Small sample\n",
    "\n",
    "hiddenNodes = [None]*int(96/3)\n",
    "trainingLoss = [None]*int(96/3)\n",
    "testingLoss = [None]*int(96/3)\n",
    "for i in range(int(len(d)/3)):\n",
    "    for j in range(3):\n",
    "        if j == 0:\n",
    "            hiddenNodes[i] = d[i*3]\n",
    "        elif j == 1:\n",
    "            trainingLoss[i] = d[i*3+1]\n",
    "        else:\n",
    "            testingLoss[i] = d[i*3+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiKS8P8DuLAkMIyMg0kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12f3d68d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hiddenNodes, trainingLoss, 'b', label = 'Training Data')\n",
    "plt.plot(hiddenNodes, testingLoss, 'r', label ='Testing Data')\n",
    "plt.ylim(0.8,1.5)\n",
    "plt.xlim(0,1500)\n",
    "plt.xlabel('Number of Hidden Nodes')\n",
    "plt.ylabel('Cross-Entropy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../log/model_full_log.txt', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEKCAYAAAA1qaOTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVNraAeUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12e97bcf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df.iloc[:1000,2], df.iloc[:1000,3])\n",
    "#plt.ylim(0.8,1.5)\n",
    "#plt.xlim(0,1500)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cross-Entropy')\n",
    "#plt.legend()\n",
    "plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))\n",
    "plt.gca().xaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
