{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This project consists of three notebooks. Together the three notebooks build a neural network that evaluates the board position in chess.\n",
    "\n",
    "The first notebook ParseData reads in the data in pgn format, converts it to binary vectors and then saves the formatted data. The second notebook NN builds a feedforward neural network that predicts the probability that a board position is win, draw or lose for white. The third notebook analyzes the formatted data. It performs some low-level and high-level checks that the data was formatted properly. It also outputs some graphs and statistics about the data. AWS is used to parse the data and train and test the neural network.\n",
    "\n",
    "**Sections:**\n",
    "\n",
    "1. Data Wrangling\n",
    "\n",
    "2. Fit Neural Network\n",
    "\n",
    "3. Test Neural Network\n",
    "\n",
    "4. Final Graphs and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load packages\n",
    "import sys\n",
    "sys.path.append(\"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/\")\n",
    "import boto3\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import vstack as vstack\n",
    "import chess, chess.pgn\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "BOARD_LENGTH = 768 #chess board is 8 x 8 and 12 different pieces\n",
    "\n",
    "## Vector representation of chess board\n",
    "# v = 1 x BOARD_LENGTH\n",
    "#\n",
    "# White = Upper Case, black = lower case\n",
    "# Piece order: P, N, B, R, Q, K, p, n, b, r, q, k\n",
    "# Board order:\n",
    "#    Start at square a1. Move across the columns to square h1.\n",
    "#    Then go up a row to square a2. Move across the columns to square h2.\n",
    "#    Repeat until square h8\n",
    "#    i.e. 0 - a1, 1 - b1, ..., 7 - h1, 8 - a2, ..., 63 - h8\n",
    "#\n",
    "# Board vector indices: \n",
    "# v[0,...,63] = P, v[64,...,127] = N, ..., v[704,...,767] = k\n",
    "# v[0,...,7] = row 1; v[8,...,15] = row 2, ..., v[56,...,63] = row 8\n",
    "# v[0] = col a, v[1] = col b, ..., v[7] = col h\n",
    "\n",
    "PIECE_OFFSETS = {'P': 0, 'N': 64, 'B': 128, 'R': 192, 'Q': 256, 'K': 320,\n",
    "                 'p': 384, 'n': 448, 'b': 512, 'r': 576, 'q': 640, 'k': 704}\n",
    "\n",
    "RESULTS = {'1-0': 1,'1/2-1/2': 0,'0-1': -1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "\n",
    "In this section, we read in the data and reformat it from chess portable game notation (pgn) to matrix form so that can the data can be fed through a neural network. Specifically, we convert each board position in each game into binary vectors encoded as above. The data is in 10 pgn files by year. We loop through the pgn files. For each pgn file, we open it and loop through the games. For each game, we encode all the board positions. In addition, we record statistics about the game (see below). The board positions are converted to a compressed sparse row matrix since the majority of the values are zero. Given any board position, there are at most 32 pieces, which means the density of the vector is at most 32/768 = 4.17%. We parallelize parsing the data using the multiprocess pacakge.\n",
    "\n",
    "**Statistics About the Data**\n",
    "\n",
    "1. Number of games\n",
    "2. Shortest game, average game, longest game in terms of # of moves\n",
    "3. Count of time controls\n",
    "4. difference in ratings, min, ave, max\n",
    "5. num of white wins, draws and loses\n",
    "\n",
    "**References**\n",
    "\n",
    "Portable Game Notation (PGN): https://en.wikipedia.org/wiki/Portable_Game_Notation\n",
    "\n",
    "Forsythâ€“Edwards Notation (FEN): https://en.wikipedia.org/wiki/Forsyth%E2%80%93Edwards_Notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# functions to help parse pgn files\n",
    "\n",
    "def convertBoardToVec(board):\n",
    "    '''convertBoardToVec(board object) -> array\n",
    "        \n",
    "        board object = object of Board Class from chess,\n",
    "        array = 1d np array of length BOARD_LENGTH\n",
    "        \n",
    "    This function loops converts a board to its corresponding vector representation\n",
    "    '''\n",
    "    \n",
    "    v = np.zeros(BOARD_LENGTH, dtype = np.int8)\n",
    "\n",
    "    pieces = board.piece_map()\n",
    "    for sq in pieces:\n",
    "        piece = pieces[sq]\n",
    "        ind = PIECE_OFFSETS[piece.symbol()] + sq\n",
    "        v[ind] = 1\n",
    "        \n",
    "    return(v)\n",
    "\n",
    "def parseGame(game):\n",
    "    '''parseGame(game object) -> (sparse matrix, list)\n",
    "        \n",
    "        game object = object of Game class from chess,\n",
    "        sparse matrix = numpy csr matrix encoding the sequence of board positions,\n",
    "        list = length 4, statistics about the game\n",
    "        \n",
    "    This function loops through the moves in a game and\n",
    "    converts the sequence of board positions to a spare matrix.\n",
    "    In addition returns statistics about the game.\n",
    "    Returns (None, None) if game has no half moves.\n",
    "    '''\n",
    "    \n",
    "    board = game.board()\n",
    "    \n",
    "    #default values\n",
    "    M = None\n",
    "    stats = [0]*4\n",
    "    boardList = []\n",
    "\n",
    "    mainLine = game.main_line()\n",
    "    for i, halfMove in enumerate(mainLine): #mainLine is a generator object\n",
    "        \n",
    "        if i == 0:\n",
    "            # get stats about game from headers\n",
    "            try:\n",
    "                h = game.headers\n",
    "                stats[0] = int(h['PlyCount'])\n",
    "                clock = h['WhiteClock']\n",
    "                if clock.count(':') == 2:\n",
    "                    stats[1] = int(datetime.strptime(clock,'%H:%M:%S.%f').minute)\n",
    "                else:\n",
    "                    stats[1] = int(datetime.strptime(clock,'%M:%S.%f').second/60)\n",
    "                stats[2] = int(h['WhiteElo']) - int(h['BlackElo'])\n",
    "                stats[3] = RESULTS[h['Result']]\n",
    "            except (KeyError, TypeError, ValueError):\n",
    "                continue\n",
    "                #stats = [np.nan]*4\n",
    "        \n",
    "        # convert sequence of board positions into 2-d binary array\n",
    "        board.push(halfMove)\n",
    "        #combine board vector with result\n",
    "        l = np.concatenate((convertBoardToVec(board), np.array([stats[3]])))\n",
    "        boardList.append(l)\n",
    "    \n",
    "    if boardList != []:\n",
    "        M = csr_matrix(np.stack(boardList, axis = 0), dtype=np.int8) #sparse array\n",
    "        #M = np.stack(boardList, axis = 0) #dense array\n",
    "    \n",
    "    return(M, stats)\n",
    "\n",
    "def parseChunk(pgnFile, chunkInfo):\n",
    "    '''returns list of length 2 [boardMatrix, gameStats]\n",
    "    \n",
    "    pgnFile - str: name of pgn file to parse\n",
    "    chunkInfo - 3-stuple of ints: (startingGameNum, startingOffset, totGames) \n",
    "    boardMatrix - sparse array: sparse matrix of the enconded board positions\n",
    "    gameStats - information from the headers about each game\n",
    "    \n",
    "    This function parse the section of games in the pgn file specified in chunkInfo\n",
    "    '''\n",
    "    \n",
    "    handle = open(pgnFile)\n",
    "    \n",
    "    # unpack tuple\n",
    "    startingGameNum, startingOffset, totGames = chunkInfo\n",
    "    \n",
    "    # change file object's position \n",
    "    handle.seek(startingOffset)\n",
    "    \n",
    "    # pandas dataframe to store statistics about the data\n",
    "    gamesStats = pd.DataFrame(data = 0, index = range(startingGameNum, startingGameNum + totGames),\n",
    "                             columns = ['Moves','Clock','RatingDiff','Result'])\n",
    "    \n",
    "    # sparse matrix to hold sequence of boards from all games\n",
    "    gamesMat = csr_matrix((0, BOARD_LENGTH + 1), dtype = np.int8)\n",
    "    \n",
    "    # read and parse games\n",
    "    for i in range(startingGameNum, startingGameNum + totGames):\n",
    "        # read in game\n",
    "        game = chess.pgn.read_game(handle)\n",
    "\n",
    "        # get sparse matrix and stats for game\n",
    "        gameMat, gameStats = parseGame(game)\n",
    " \n",
    "        # save\n",
    "        gamesMat = vstack([gamesMat, gameMat], format = 'csr')\n",
    "        gamesStats.loc[i,:] = gameStats\n",
    "\n",
    "    handle.close()\n",
    "\n",
    "    return([gamesMat, gamesStats])\n",
    "\n",
    "def parseFile(pgnFile):\n",
    "    '''Saves two files - one for the vector of board positions and one for the game stats\n",
    "    \n",
    "    pgnFile - str: path to pgn file\n",
    "    '''\n",
    "\n",
    "    # get info about how to split up file into chunks\n",
    "    nChunks = os.cpu_count()\n",
    "    chunkInfo = prepareFile(pgnFile, nChunks)\n",
    "    chunkList = [(pgnFile, chunkInfo[i]) for i in range(nChunks)]\n",
    "    \n",
    "    # parse file by chunk\n",
    "    workers = mp.Pool(processes = nChunks)\n",
    "    result = workers.starmap(parseChunk, chunkList, nChunks)\n",
    "    workers.close()\n",
    "    workers.join()\n",
    "    \n",
    "    # recombine chunks\n",
    "    gamesMat = vstack([result[i][0] for i in range(nChunks)]) #sparse matrices of enconded board positions\n",
    "    gamesStats = pd.concat([result[i][1] for i in range(nChunks)]) #data frames of game stats\n",
    "    \n",
    "    # save\n",
    "    outMat = pgnFile.rstrip('.pgn') + '_mat.pickle.gz'\n",
    "    outStats = pgnFile.rstrip('.pgn') + '_stats.pickle'\n",
    "    \n",
    "    with gzip.open(outMat, 'wb') as f:\n",
    "        f.write(pickle.dumps(gamesMat, pickle.HIGHEST_PROTOCOL))\n",
    "    \n",
    "    gamesStats.to_pickle(outStats)\n",
    "    \n",
    "    return\n",
    "    \n",
    "def prepareFile(pgnFileName, nChunks, nGames = 500000):\n",
    "    '''prepareFile(fileName, nChunks, nGames) -> list of length n of 3-tuples\n",
    "    \n",
    "    pgnFileName - str: name of the pgn file to split into n chunks\n",
    "    nChunks - int: number of chunks to break file into\n",
    "    nGames - int: upper bound on number of games in the file\n",
    "    tuple - (int, int, int): (startingGameNum, startingOffset, totGames)\n",
    "    '''\n",
    "    \n",
    "    pgnFile = open(pgnFileName)\n",
    "    \n",
    "    # get game numbers and offsets\n",
    "    totGames = 0\n",
    "    offsets = np.empty(nGames, dtype = np.int_)\n",
    "    \n",
    "    for offset in chess.pgn.scan_offsets(pgnFile):\n",
    "        totGames = totGames + 1\n",
    "        offsets[totGames - 1] = offset\n",
    "    \n",
    "    chunkSize = totGames // nChunks\n",
    "    tail = int(totGames - chunkSize * nChunks)\n",
    "    \n",
    "    l = []\n",
    "    for i in range(nChunks - 1):\n",
    "            l.append((i * chunkSize + 1, offsets[i * chunkSize], chunkSize))\n",
    "\n",
    "    l.append(((nChunks - 1) * chunkSize + 1, offsets[(nChunks - 1) * chunkSize], chunkSize + tail))\n",
    "    \n",
    "    pgnFile.close()\n",
    "    \n",
    "    return(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to process 41.47571086883545\n"
     ]
    }
   ],
   "source": [
    "def main(dataDir):\n",
    "    # get list of pgn files\n",
    "    pgnFiles = []\n",
    "    dataFiles = os.listdir(dataDir)\n",
    "    \n",
    "    for dataFile in dataFiles:\n",
    "        if dataFile.endswith('.pgn'):\n",
    "            pgnFiles.append(os.path.join(dataDir,dataFile))\n",
    "\n",
    "    pgnFiles.sort()\n",
    "\n",
    "    workers = []\n",
    "    for i in range(len(pgnFiles)):\n",
    "        worker = mp.Process(target=parseFile, args=(pgnFiles[i],), daemon = False)\n",
    "        worker.start()\n",
    "        workers.append(worker)\n",
    "    for worker in workers:\n",
    "        worker.join()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    dataDir = '../test'\n",
    "    s = time.time()\n",
    "    main(dataDir)\n",
    "    e = time.time()\n",
    "    print(\"Total time to process {}\".format(e-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# decouple: create info about chunks using multiple cores, then take info about chunks and process using multiple cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes for Report\n",
    "\n",
    "1. Vector encoding of board positions\n",
    "2. Storage saving from using compressed sparse row matrices\n",
    "3. Estimate of time to read 2007 data based on first 1000 games\n",
    "4. Parallel processing of the data\n",
    "5. graphs - % of white wins, black wins and draws\n",
    "6. scatter plot rating diff and white win %\n",
    "7. num og games, ave moves per game\n",
    "8. randomly check 10 board positions and compare with printed board,\n",
    "   - max # of 1s for all the boards, ave and min\n",
    "   - sum of moves = num of rows in sparse matrix\n",
    "9. reading first 10,000 games, serial vs parallel\n",
    "\n",
    "**Notes on data**\n",
    "\n",
    "1. Didn't use games between low rated players because low rated players could have relationships that are bad to learn\n",
    "    for example, a if white is up a rook, this position should lead to a win 99%+ of the time, but with bad players this position might lead to a win only 50% of the time because bad players blunder a lot\n",
    "2. further training = neural net plays against itself and one of the player's make a mistake occassionally\n",
    "3. skill level game = sum of 2 players and use this as a weight, rating diff between players\n",
    "4. not super predictable playing style from comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions\n",
    "\n",
    "This section contains functions that gather information about the execution of the main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculates time for function to execute\n",
    "# look up profiling python like a boss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readGame(pgnFileH):\n",
    "    '''readGame(handle to pgn file) -> next game object\n",
    "    \n",
    "    Generator function that creates iterator to loop through games\n",
    "    '''\n",
    "    \n",
    "    game = chess.pgn.read_game(pgnFileH)\n",
    "    while game != None:\n",
    "        yield game\n",
    "        game = chess.pgn.read_game(pgnFileH)\n",
    "        \n",
    "def readGame2(pgnFile, gameNum, gameOffset):\n",
    "    '''random access version of read game - for parallel processing\n",
    "    \n",
    "    pgnGames - handle to pgn file\n",
    "    gameNum - game number\n",
    "    gameOffset - file offset\n",
    "    '''\n",
    "    \n",
    "    # move to location in file and read in game\n",
    "    pgnGames = open(pgnFile)\n",
    "    pgnGames.seek(gameOffset)\n",
    "    game = chess.pgn.read_game(pgnGames)\n",
    "    \n",
    "    # get sparse matrix and stats for game\n",
    "    gameMat, gameStats = parseGame(game)  \n",
    "    \n",
    "    return((gameMat, gameStats, gameNum))\n",
    "        \n",
    "def readGames(pgnFileH):\n",
    "    '''readGames(handle to pgn file) -> tuple (sparse matrix of all games, dataframe of stats)\n",
    "    '''\n",
    "    \n",
    "    # pandas dataframe to store statistics about the data\n",
    "    # at most 1 M per year based on skimming through the largest file 2013\n",
    "    dataStats = pd.DataFrame(data = 0, index = range(3*10**4),\n",
    "                             columns = ['Moves','Clock','RatingDiff','Result'])\n",
    "    \n",
    "    # sparse matrix to hold sequence of boards from all games\n",
    "    gamesMat = csr_matrix((0, BOARD_LENGTH + 1), dtype = np.int8)\n",
    "    \n",
    "    for i, game in enumerate(readGame(pgnFileH)):\n",
    "        \n",
    "        if i > 10000:\n",
    "            break\n",
    "            \n",
    "        # get sparse matrix and stats for game\n",
    "        gameMat, gameStats = parseGame(game)\n",
    "        \n",
    "        # add game matrix and game stats to matrix and dataframe for all games\n",
    "        if gameMat != None:\n",
    "            gamesMat = vstack([gamesMat, gameMat], format = 'csr')\n",
    "            dataStats.iloc[i,:] = gameStats\n",
    "        \n",
    "    return(gamesMat, dataStats.iloc[0:i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# serial approach 20000 games\n",
    "handle = open(pgnFiles[0])\n",
    "startTime = time.time()\n",
    "a,b = readGames(handle)\n",
    "endTime = time.time()\n",
    "print(endTime - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parallelize processing of data\n",
    "# uses multiprocessing library from python standard libaray\n",
    "# pool of 4 workers (processes) are created\n",
    "# asynchronous calls to games in the pgn file are spread out among the 4 workers\n",
    "# call = read and parse a particular game\n",
    "# \n",
    "#                         -> worker1 -> parse game into sparse matrix and stats |\n",
    "#   pgn file -> read game -> worker2 -> \"                                     \" |  -> container\n",
    "#                         -> worker3 -> \"                                     \" |           \n",
    "#                         -> worker4 -> \"                                     \" |\n",
    "\n",
    "\n",
    "# pandas dataframe to store statistics about the data\n",
    "# at most 1 M per year based on skimming through the largest file 2013\n",
    "#gStats = pd.DataFrame(data = 0, index = range(10**6), columns = ['Moves','Clock','RatingDiff','Result'])\n",
    "# sparse matrix to hold sequence of boards from all games\n",
    "#gMat = csr_matrix((0, BOARD_LENGTH + 1), dtype = np.int8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s3.create_bucket(Bucket='brianlubeck', CreateBucketConfiguration={'LocationConstraint': 'us-west-1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# uploads the given file using a managed uploader, which will split up large\n",
    "# files automatically and upload parts in parallel.\n",
    "# uncomment code \n",
    "for i, f in enumerate(pgnFiles[4:]):\n",
    "    fn = 'chess/data/' + str(2011 + i) + '.pgn'\n",
    "    s3.upload_file(f, 'brianlubeck2', fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
